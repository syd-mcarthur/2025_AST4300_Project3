{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43b5d36-b656-4077-96e8-84590f6b140d",
   "metadata": {},
   "source": [
    "# Milky Way Mapper's Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8ff0b",
   "metadata": {},
   "source": [
    "## Section 7: Paper Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d457f8-beb0-4f9c-9886-de9ecdcf08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some things\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525f7b4-27eb-4abd-87c3-916ab17aef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data (may have to change this for wherever you downloaded your file)\n",
    "#in google colab you can get the file using\n",
    "#!wget https://dr19.sdss.org/sas/dr19/spectro/astra/0.6.0/summary/astraAllStarASPCAP-0.6.0.fits.gz \n",
    "\n",
    "filename='astraAllStarASPCAP-0.6.0.fits'\n",
    "tb = fits.open(filename)\n",
    "header=tb[2].header\n",
    "data = tb[2].data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f63592d-5b8d-4c71-b64b-9001481db68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "good=np.where((data['teff'] > 3700) & (data['teff'] < 5300) &\n",
    "               (data['logg'] > 0.9) & (data['logg'] < 3.3) &\n",
    "               (data['m_h_atm'] > -2.0) & (data['m_h_atm'] < 0.6) &   \n",
    "               (data['flag_bad']==False) )\n",
    "\n",
    "data_masked=data[good]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69c238-4e3a-49a3-a0e1-c945d4e3cb26",
   "metadata": {},
   "source": [
    "## Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e198e51e-627e-43a1-aca4-4b421a89b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=124340</i>\n",
       "<table id=\"table1995474364672\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>TIC</th><th>Star_type</th><th>Age</th><th>Î½max</th><th>Radius_gaia</th><th>Teff_xgboost</th><th>M_H_xgboost</th><th>Logg_xgboost</th><th>Logg_seis</th><th>E_Logg_seis</th><th>Mass_seis</th><th>E_Mass_seis</th><th>Initial_mass</th><th>Teff_rgb</th><th>Teff_rc</th><th>Median_age_rgb</th><th>Median_age_rc</th><th>E_lower_age_rgb</th><th>E_upper_age_rgb</th><th>E_lower_age_rc</th><th>E_upper_age_rc</th><th>Teff_diff</th><th>Flag</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>str5</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th></tr></thead>\n",
       "<tr><td>347020604</td><td>Clump</td><td>4.933697638292032</td><td>32.2</td><td>10.8</td><td>4766.6</td><td>-0.161</td><td>2.432</td><td>2.4173752480453827</td><td>0.0366707608673319</td><td>1.1120077414967078</td><td>0.0588614326241161</td><td>1.2303580537284051</td><td>4573.560449427352</td><td>4592.554431111989</td><td>7.362373244</td><td>4.928036510093708</td><td>6.081092717</td><td>8.892029592</td><td>4.299934128259921</td><td>6.1356166056543815</td><td>174.04556888801108</td><td>0</td></tr>\n",
       "<tr><td>365250045</td><td>RGB</td><td>5.919390103924665</td><td>33.0</td><td>10.8</td><td>4931.7</td><td>-0.342</td><td>2.455</td><td>2.4229857865111493</td><td>0.0357953759646522</td><td>1.126466677413624</td><td>0.056320640605</td><td>1.1264672739859862</td><td>4667.980210870163</td><td>4834.105313542321</td><td>5.948811656</td><td>4.27541564590489</td><td>5.120775603</td><td>7.010332121</td><td>3.7125897559954217</td><td>4.990341868284544</td><td>97.59468645767902</td><td>0</td></tr>\n",
       "<tr><td>377058143</td><td>RGB</td><td>10.659761236332615</td><td>59.1</td><td>7.3</td><td>4732.1</td><td>-0.519</td><td>2.615</td><td>2.677206425366256</td><td>0.0648094481080465</td><td>0.9241388003056158</td><td>0.0471439463924816</td><td>0.9241384053448526</td><td>4809.243666602538</td><td>4845.904744096898</td><td>11.11556225</td><td>5.653288060595535</td><td>9.53022434</td><td>12.72313934</td><td>4.950738403099905</td><td>6.798479977799735</td><td>-113.8047440968976</td><td>0</td></tr>\n",
       "<tr><td>347548024</td><td>RGB</td><td>4.2433496208314345</td><td>33.2</td><td>11.5</td><td>4634.4</td><td>-0.213</td><td>2.388</td><td>2.4218043131513705</td><td>0.0720751969086103</td><td>1.2737524436569616</td><td>0.0852469599851652</td><td>1.2737527853903323</td><td>4625.72134164397</td><td>4775.614677688445</td><td>4.196919598</td><td>3.1842561951173276</td><td>3.279495422</td><td>5.737266629</td><td>2.7003724708906987</td><td>3.926199760609352</td><td>-141.2146776884456</td><td>0</td></tr>\n",
       "<tr><td>328321210</td><td>Clump</td><td>5.297976079237009</td><td>35.7</td><td>9.6</td><td>4982.0</td><td>-0.526</td><td>2.441</td><td>2.4671643779400427</td><td>0.0755464565388593</td><td>0.9853531626679212</td><td>0.0677079590734425</td><td>1.121116190405825</td><td>4737.2709053692715</td><td>4762.055765851048</td><td>9.131354832</td><td>5.481214180765681</td><td>6.619391066</td><td>11.17929356</td><td>4.57496878200937</td><td>6.826530999798273</td><td>219.9442341489521</td><td>0</td></tr>\n",
       "<tr><td>328321103</td><td>RGB</td><td>3.76901613056093</td><td>34.5</td><td>11.4</td><td>4765.0</td><td>-0.277</td><td>2.533</td><td>2.438719284222579</td><td>0.0355087401732596</td><td>1.3014095644450476</td><td>0.0659512559797257</td><td>1.301409615256684</td><td>4669.883118807332</td><td>4814.012809659391</td><td>3.7183394</td><td>2.964010779639734</td><td>3.222621332</td><td>4.398228001</td><td>2.51085645776994</td><td>3.520642797490074</td><td>-49.01280965939077</td><td>0</td></tr>\n",
       "<tr><td>328324062</td><td>Clump</td><td>2.303632505100647</td><td>41.3</td><td>11.3</td><td>4792.0</td><td>0.085</td><td>2.617</td><td>2.5205598637381987</td><td>0.0266418863144747</td><td>1.5438382675435354</td><td>0.0669944467135548</td><td>1.6114631436790468</td><td>4552.67752843955</td><td>4567.434071459611</td><td>2.700422808</td><td>2.2357112051063632</td><td>2.255954628</td><td>3.155200636</td><td>1.9961451072036724</td><td>2.638300639580447</td><td>224.565928540389</td><td>0</td></tr>\n",
       "<tr><td>328400618</td><td>Clump</td><td>2.159728298323744</td><td>44.1</td><td>10.5</td><td>4910.2</td><td>-0.319</td><td>2.472</td><td>2.557435937807216</td><td>0.0739867137774788</td><td>1.4511074516675977</td><td>0.0926043469167527</td><td>1.5165343396975142</td><td>4767.690838544538</td><td>4778.114861413547</td><td>2.561181642</td><td>2.157582282377099</td><td>2.082416797</td><td>3.109146383</td><td>1.7850147949917456</td><td>2.6517500725099072</td><td>132.08513858645256</td><td>0</td></tr>\n",
       "<tr><td>328255103</td><td>Clump</td><td>6.418514994888695</td><td>31.9</td><td>10.8</td><td>4686.6</td><td>0.019</td><td>2.433</td><td>2.406553604071016</td><td>0.0559847430029249</td><td>1.0846413740056715</td><td>0.0674371343640133</td><td>1.18744043140101</td><td>4471.252872082005</td><td>4487.596554271885</td><td>9.075683921</td><td>6.586728636664553</td><td>7.526636104</td><td>11.69375071</td><td>5.35273124007062</td><td>7.587960124712628</td><td>199.00344572811537</td><td>0</td></tr>\n",
       "<tr><td>402043780</td><td>Clump</td><td>2.8382182492114003</td><td>38.3</td><td>10.5</td><td>4951.0</td><td>-0.458</td><td>2.489</td><td>2.492313215654373</td><td>0.0523395409874911</td><td>1.249041447877655</td><td>0.0710125829445473</td><td>1.3609932130546345</td><td>4770.1317257509845</td><td>4786.738389696614</td><td>3.683375734</td><td>2.8000484870144087</td><td>3.089925799</td><td>4.4959048</td><td>2.417840951292972</td><td>3.346645352200174</td><td>164.26161030338608</td><td>0</td></tr>\n",
       "<tr><td>328401761</td><td>RGB</td><td>8.101187282505668</td><td>30.2</td><td>11.0</td><td>4580.3</td><td>-0.233</td><td>2.343</td><td>2.37959365392587</td><td>0.076340075284416</td><td>1.0574602728500353</td><td>0.0761499123955482</td><td>1.0574604286752458</td><td>4578.682956918866</td><td>4598.231978539404</td><td>8.333970598</td><td>5.535317421130186</td><td>6.279247553</td><td>11.18407785</td><td>4.607950398494398</td><td>7.005037930804026</td><td>-17.931978539403644</td><td>0</td></tr>\n",
       "<tr><td>328401823</td><td>Clump</td><td>8.321739648177305</td><td>28.6</td><td>10.8</td><td>4639.6</td><td>0.026</td><td>2.41</td><td>2.355434543716802</td><td>0.0578663791641111</td><td>0.9641999538686676</td><td>0.0615799189420187</td><td>1.1061495073331475</td><td>4420.79621921404</td><td>4449.378299447831</td><td>14.15319737</td><td>8.257265571856447</td><td>11.09288731</td><td>17.04916702</td><td>6.604412551707767</td><td>9.799701560215968</td><td>190.22170055216975</td><td>0</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>99646742</td><td>Clump</td><td>5.423964520454567</td><td>34.1</td><td>10.5</td><td>4696.7</td><td>-0.086</td><td>2.423</td><td>2.4382817692011964</td><td>0.033391847914439</td><td>1.1029235338837318</td><td>0.0533057223530582</td><td>1.216818587375791</td><td>4541.1525195647155</td><td>4559.231860346983</td><td>7.64070121</td><td>5.37336048067821</td><td>6.894308608</td><td>9.550235525</td><td>4.658134332532128</td><td>6.537669179946954</td><td>137.4681396530168</td><td>0</td></tr>\n",
       "<tr><td>415687264</td><td>RGB</td><td>2.478919826011453</td><td>73.1</td><td>8.6</td><td>4644.4</td><td>0.142</td><td>2.676</td><td>2.769536323590333</td><td>0.0329579999650657</td><td>1.5864204550022512</td><td>0.0730805083547152</td><td>1.5864197755650873</td><td>4659.446338973617</td><td>4675.097086525743</td><td>2.50818079</td><td>2.158105918961662</td><td>2.13475473</td><td>2.930576681</td><td>1.9004340449168156</td><td>2.438444231344879</td><td>-30.697086525743543</td><td>0</td></tr>\n",
       "<tr><td>439360282</td><td>Clump</td><td>6.574989820526875</td><td>32.7</td><td>10.4</td><td>4773.5</td><td>-0.058</td><td>2.491</td><td>2.416985861354139</td><td>0.0348000854524985</td><td>1.030237952025892</td><td>0.0508032589713899</td><td>1.1607225870029003</td><td>4499.609988024315</td><td>4522.35756175027</td><td>10.42039061</td><td>6.57749952421746</td><td>8.938170228</td><td>12.41013859</td><td>5.657141141891809</td><td>7.77133558569585</td><td>251.14243824972985</td><td>0</td></tr>\n",
       "<tr><td>24293754</td><td>Clump</td><td>7.270499767640112</td><td>30.9</td><td>10.2</td><td>4680.1</td><td>-0.2</td><td>2.428</td><td>2.399207980219463</td><td>0.0298296961867419</td><td>0.9512470957539596</td><td>0.0441236882134543</td><td>1.0956080340537082</td><td>4548.956849105674</td><td>4579.390412244217</td><td>12.42068752</td><td>7.310600524515545</td><td>10.69207048</td><td>15.40925913</td><td>6.310366637090926</td><td>8.712502028260396</td><td>100.7095877557831</td><td>0</td></tr>\n",
       "<tr><td>444151014</td><td>RGB</td><td>1.3293989221533338</td><td>42.0</td><td>12.7</td><td>4564.5</td><td>0.235</td><td>2.428</td><td>2.5241027057740677</td><td>0.0302942508281642</td><td>1.9660527727614991</td><td>0.1066372801170731</td><td>1.9660528317165893</td><td>4551.681217126331</td><td>4558.626214039348</td><td>1.337344976</td><td>1.2193055256945164</td><td>1.107826687</td><td>1.66771992</td><td>1.0892608398607586</td><td>1.455594566352458</td><td>5.87378596065173</td><td>0</td></tr>\n",
       "<tr><td>439387397</td><td>RGB</td><td>10.886531443589943</td><td>38.6</td><td>9.3</td><td>4631.1</td><td>-0.248</td><td>2.499</td><td>2.489396578020239</td><td>0.0508134259270761</td><td>0.9733018061196635</td><td>0.0521761267719925</td><td>0.9733012519116058</td><td>4620.716367755734</td><td>4650.601883450058</td><td>10.99454201</td><td>6.314006485124088</td><td>9.032860348</td><td>13.20527487</td><td>5.211545198833982</td><td>7.635994733477046</td><td>-19.501883450057903</td><td>0</td></tr>\n",
       "<tr><td>439387373</td><td>RGB</td><td>13.559665913368113</td><td>52.9</td><td>7.7</td><td>4598.5</td><td>-0.206</td><td>2.636</td><td>2.6307613177683287</td><td>0.0258131672540484</td><td>0.9239059902913592</td><td>0.0373936421046703</td><td>0.923906214083602</td><td>4641.654812571993</td><td>4680.746214005319</td><td>13.70737483</td><td>7.753563029049198</td><td>12.2628135</td><td>15.12569441</td><td>6.896534907227312</td><td>8.865732312274117</td><td>-82.24621400531942</td><td>0</td></tr>\n",
       "<tr><td>415686794</td><td>Clump</td><td>3.5268592139224655</td><td>37.9</td><td>10.9</td><td>4773.3</td><td>0.112</td><td>2.631</td><td>2.483340981191912</td><td>0.0267072980726848</td><td>1.3184965052627895</td><td>0.0575078402125955</td><td>1.4340694281462223</td><td>4488.851912716716</td><td>4508.089132079645</td><td>4.837948927</td><td>3.4995127765543605</td><td>4.256064234</td><td>5.586369343</td><td>2.954016975950612</td><td>4.00273702323879</td><td>265.21086792035476</td><td>0</td></tr>\n",
       "<tr><td>99837810</td><td>Clump</td><td>11.042183147979149</td><td>28.1</td><td>10.4</td><td>4605.9</td><td>0.016</td><td>2.431</td><td>2.3499336495620113</td><td>0.0712269930351832</td><td>0.8828467704108918</td><td>0.0635229717437992</td><td>1.0255068506336564</td><td>4399.246020147388</td><td>4431.823017834595</td><td>19.82332468</td><td>10.657076041429718</td><td>15.87245997</td><td>24.47288804</td><td>8.222377635684587</td><td>13.862395309695891</td><td>174.07698216540484</td><td>0</td></tr>\n",
       "<tr><td>99821552</td><td>RGB</td><td>2.1627981000040437</td><td>25.0</td><td>15.1</td><td>4420.4</td><td>-0.067</td><td>2.14</td><td>2.282880926371518</td><td>0.0817620341485557</td><td>1.5948501340660617</td><td>0.1271293994256553</td><td>1.5948499544670982</td><td>4521.13258638862</td><td>4530.195881339838</td><td>2.059770856</td><td>1.8605694698050377</td><td>1.656739446</td><td>2.680530158</td><td>1.4738695107846194</td><td>2.5179584189392616</td><td>-109.79588133983816</td><td>0</td></tr>\n",
       "<tr><td>441029961</td><td>Clump</td><td>4.068854769155727</td><td>35.5</td><td>10.6</td><td>4782.2</td><td>-0.251</td><td>2.454</td><td>2.4586662614356354</td><td>0.0272611630299921</td><td>1.1780481987255331</td><td>0.0525955456468396</td><td>1.279547727713048</td><td>4647.035647055904</td><td>4663.605199793464</td><td>5.528992072</td><td>3.875785579258347</td><td>4.639599327</td><td>6.24384432</td><td>3.4206135944114515</td><td>4.660127921049435</td><td>118.59480020653608</td><td>0</td></tr>\n",
       "<tr><td>441015317</td><td>RGB</td><td>10.13177954</td><td>25.4</td><td>12.1</td><td>4410.4</td><td>0.043</td><td>2.251</td><td>2.298070483513228</td><td>0.0446639679644</td><td>1.0605381308578825</td><td>0.0621831423234216</td><td>1.0605384566787168</td><td>4412.812108453358</td><td>4428.713056662758</td><td>10.11310758</td><td>7.127798454945256</td><td>8.257605623</td><td>12.28754288</td><td>5.930333252764051</td><td>8.430542558191812</td><td>-18.31305666275875</td><td>0</td></tr>\n",
       "<tr><td>99818843</td><td>RGB</td><td>6.006672813122813</td><td>30.3</td><td>11.4</td><td>4484.3</td><td>-0.292</td><td>2.301</td><td>2.37918647277568</td><td>0.0789505179281383</td><td>1.134700334062554</td><td>0.0825100846064691</td><td>1.1347006565422713</td><td>4621.617923416667</td><td>4639.586052550128</td><td>6.183338205</td><td>4.118140285608963</td><td>4.912764406</td><td>7.972203552</td><td>3.446298354171621</td><td>5.439509135147377</td><td>-155.28605255012826</td><td>0</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=124340>\n",
       "   TIC    Star_type        Age          Î½max  ...   E_lower_age_rc     E_upper_age_rc        Teff_diff       Flag\n",
       "  int64      str5        float64       float64 ...      float64            float64             float64       int64\n",
       "--------- --------- ------------------ ------- ... ------------------ ------------------ ------------------- -----\n",
       "347020604     Clump  4.933697638292032    32.2 ...  4.299934128259921 6.1356166056543815  174.04556888801108     0\n",
       "365250045       RGB  5.919390103924665    33.0 ... 3.7125897559954217  4.990341868284544   97.59468645767902     0\n",
       "377058143       RGB 10.659761236332615    59.1 ...  4.950738403099905  6.798479977799735  -113.8047440968976     0\n",
       "347548024       RGB 4.2433496208314345    33.2 ... 2.7003724708906987  3.926199760609352  -141.2146776884456     0\n",
       "328321210     Clump  5.297976079237009    35.7 ...   4.57496878200937  6.826530999798273   219.9442341489521     0\n",
       "328321103       RGB   3.76901613056093    34.5 ...   2.51085645776994  3.520642797490074  -49.01280965939077     0\n",
       "328324062     Clump  2.303632505100647    41.3 ... 1.9961451072036724  2.638300639580447    224.565928540389     0\n",
       "328400618     Clump  2.159728298323744    44.1 ... 1.7850147949917456 2.6517500725099072  132.08513858645256     0\n",
       "328255103     Clump  6.418514994888695    31.9 ...   5.35273124007062  7.587960124712628  199.00344572811537     0\n",
       "402043780     Clump 2.8382182492114003    38.3 ...  2.417840951292972  3.346645352200174  164.26161030338608     0\n",
       "328401761       RGB  8.101187282505668    30.2 ...  4.607950398494398  7.005037930804026 -17.931978539403644     0\n",
       "328401823     Clump  8.321739648177305    28.6 ...  6.604412551707767  9.799701560215968  190.22170055216975     0\n",
       "      ...       ...                ...     ... ...                ...                ...                 ...   ...\n",
       " 99646742     Clump  5.423964520454567    34.1 ...  4.658134332532128  6.537669179946954   137.4681396530168     0\n",
       "415687264       RGB  2.478919826011453    73.1 ... 1.9004340449168156  2.438444231344879 -30.697086525743543     0\n",
       "439360282     Clump  6.574989820526875    32.7 ...  5.657141141891809   7.77133558569585  251.14243824972985     0\n",
       " 24293754     Clump  7.270499767640112    30.9 ...  6.310366637090926  8.712502028260396   100.7095877557831     0\n",
       "444151014       RGB 1.3293989221533338    42.0 ... 1.0892608398607586  1.455594566352458    5.87378596065173     0\n",
       "439387397       RGB 10.886531443589943    38.6 ...  5.211545198833982  7.635994733477046 -19.501883450057903     0\n",
       "439387373       RGB 13.559665913368113    52.9 ...  6.896534907227312  8.865732312274117  -82.24621400531942     0\n",
       "415686794     Clump 3.5268592139224655    37.9 ...  2.954016975950612   4.00273702323879  265.21086792035476     0\n",
       " 99837810     Clump 11.042183147979149    28.1 ...  8.222377635684587 13.862395309695891  174.07698216540484     0\n",
       " 99821552       RGB 2.1627981000040437    25.0 ... 1.4738695107846194 2.5179584189392616 -109.79588133983816     0\n",
       "441029961     Clump  4.068854769155727    35.5 ... 3.4206135944114515  4.660127921049435  118.59480020653608     0\n",
       "441015317       RGB        10.13177954    25.4 ...  5.930333252764051  8.430542558191812  -18.31305666275875     0\n",
       " 99818843       RGB  6.006672813122813    30.3 ...  3.446298354171621  5.439509135147377 -155.28605255012826     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESS\n",
    "tessraw = Table.read(\"Theodoridis2025.csv\", format=\"ascii\")\n",
    "#this one has an age column in Gyr already so we're just going to rename it Age\n",
    "tessraw['Final_age'].name='Age'\n",
    "hasagetess=np.where((tessraw['Age']==tessraw['Age']) & (tessraw['Age']>0.1) &(tessraw['Flag']==0))\n",
    "tess=tessraw[hasagetess]\n",
    "tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c979c407-4098-406d-9ef0-b322b985bc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><i>Table length=6529</i>\n",
       "<table id=\"table1999288950256\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>KIC</th><th>2MASS</th><th>Teff</th><th>e_Teff</th><th>FeH</th><th>e_FeH</th><th>AFe</th><th>e_AFe</th><th>Nmax</th><th>e_Nmax</th><th>Dnu</th><th>e_Dnu</th><th>ES</th><th>Fdnu</th><th>e_Fdnu</th><th>M(cor)</th><th>e_M(cor)-ran</th><th>e_M(cor)-sys</th><th>R(cor)</th><th>e_R(cor)-ran</th><th>e_R(cor)-sys</th><th>logg(seis)</th><th>e_logg(seis)-ran</th><th>e_logg(seis)-sys</th><th>Rho</th><th>e_Rho-ran</th><th>e_Rho-sys</th><th>LogAge</th><th>E_LogAge</th><th>e_LogAge</th><th>Av</th><th>e_Av</th><th>Notes</th><th>Age</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th>K</th><th>K</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>dex(---)</th><th>uHz</th><th></th><th>uHz</th><th></th><th></th><th></th><th></th><th>Msun</th><th></th><th></th><th>Rsun</th><th></th><th></th><th>dex(cm / s2)</th><th></th><th></th><th>g / cm3</th><th></th><th></th><th>Myr</th><th>Myr</th><th>Myr</th><th>mag</th><th>mag</th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>str18</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str8</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str18</th><th>float64</th></tr></thead>\n",
       "<tr><td>1027110</td><td>2M19250937+3644599</td><td>4177.6</td><td>51.8</td><td>-0.232</td><td>0.025</td><td>0.205</td><td>0.015</td><td>6.496</td><td>0.015</td><td>1.132</td><td>0.029</td><td>RGB</td><td>1.0458</td><td>0.0006</td><td>0.985</td><td>0.126</td><td>0.044</td><td>23.412</td><td>0.06</td><td>0.017</td><td>1.692</td><td>0.007</td><td>0.007</td><td>0.0001082</td><td>0.058</td><td>0.008</td><td>4.002</td><td>0.205</td><td>-0.189</td><td>0.269</td><td>0.121</td><td>SeisUnc</td><td>10.046157902783946</td></tr>\n",
       "<tr><td>1027337</td><td>2M19252021+3647118</td><td>4636.0</td><td>67.3</td><td>0.275</td><td>0.024</td><td>0.023</td><td>0.01</td><td>73.975</td><td>0.009</td><td>6.991</td><td>0.013</td><td>RGB</td><td>1.0333</td><td>0.0003</td><td>1.227</td><td>0.063</td><td>0.038</td><td>7.544</td><td>0.029</td><td>0.014</td><td>2.772</td><td>0.005</td><td>0.007</td><td>0.004029</td><td>0.026</td><td>0.007</td><td>3.798</td><td>0.099</td><td>-0.09</td><td>0.214</td><td>0.071</td><td>...</td><td>6.2805835881331795</td></tr>\n",
       "<tr><td>1160789</td><td>2M19233280+3652207</td><td>4729.6</td><td>72.3</td><td>-0.257</td><td>0.034</td><td>0.188</td><td>0.015</td><td>25.209</td><td>0.015</td><td>3.545</td><td>0.011</td><td>RC</td><td>0.9965</td><td>0.0324</td><td>0.875</td><td>0.147</td><td>0.082</td><td>10.86</td><td>0.071</td><td>0.025</td><td>2.308</td><td>0.007</td><td>0.01</td><td>0.0009635</td><td>0.069</td><td>0.008</td><td>3.889</td><td>0.133</td><td>-0.146</td><td>0.009</td><td>0.074</td><td>...</td><td>7.744617978025183</td></tr>\n",
       "<tr><td>1161447</td><td>2M19241746+3651460</td><td>4776.1</td><td>86.2</td><td>0.058</td><td>0.029</td><td>-0.006</td><td>0.013</td><td>37.066</td><td>0.027</td><td>4.153</td><td>0.011</td><td>RC</td><td>1.003</td><td>0.0238</td><td>1.46</td><td>0.135</td><td>0.076</td><td>11.54</td><td>0.059</td><td>0.022</td><td>2.478</td><td>0.012</td><td>0.01</td><td>0.00134</td><td>0.052</td><td>0.008</td><td>3.396</td><td>0.166</td><td>-0.145</td><td>0.4</td><td>0.086</td><td>...</td><td>2.48885731828239</td></tr>\n",
       "<tr><td>1161618</td><td>2M19242614+3648478</td><td>4742.0</td><td>72.1</td><td>0.064</td><td>0.029</td><td>0.005</td><td>0.012</td><td>33.926</td><td>0.01</td><td>4.093</td><td>0.012</td><td>RC</td><td>1.001</td><td>0.0033</td><td>1.183</td><td>0.063</td><td>0.077</td><td>10.879</td><td>0.028</td><td>0.023</td><td>2.438</td><td>0.005</td><td>0.01</td><td>0.001296</td><td>0.026</td><td>0.008</td><td>3.639</td><td>0.064</td><td>-0.069</td><td>0.199</td><td>0.074</td><td>...</td><td>4.355118736855684</td></tr>\n",
       "<tr><td>1162220</td><td>2M19245791+3653298</td><td>4190.1</td><td>51.7</td><td>0.083</td><td>0.021</td><td>0.07</td><td>0.011</td><td>11.0</td><td>0.01</td><td>1.669</td><td>0.011</td><td>RGB</td><td>1.0484</td><td>0.0004</td><td>1.007</td><td>0.055</td><td>0.044</td><td>18.175</td><td>0.024</td><td>0.017</td><td>1.922</td><td>0.005</td><td>0.007</td><td>0.0002364</td><td>0.021</td><td>0.008</td><td>4.056</td><td>0.087</td><td>-0.083</td><td>0.181</td><td>0.073</td><td>...</td><td>11.37627285823431</td></tr>\n",
       "<tr><td>1162746</td><td>2M19252639+3649116</td><td>4798.1</td><td>75.6</td><td>-0.388</td><td>0.038</td><td>0.229</td><td>0.017</td><td>27.798</td><td>0.015</td><td>3.763</td><td>0.01</td><td>RC</td><td>0.9972</td><td>0.0281</td><td>0.941</td><td>0.131</td><td>0.08</td><td>10.688</td><td>0.062</td><td>0.024</td><td>2.354</td><td>0.007</td><td>0.01</td><td>0.001087</td><td>0.06</td><td>0.008</td><td>3.786</td><td>0.139</td><td>-0.131</td><td>0.172</td><td>0.075</td><td>...</td><td>6.109420249055721</td></tr>\n",
       "<tr><td>1163114</td><td>2M19254564+3650475</td><td>4285.8</td><td>54.4</td><td>0.297</td><td>0.02</td><td>0.025</td><td>0.01</td><td>14.356</td><td>0.011</td><td>1.887</td><td>0.008</td><td>RGB</td><td>1.0396</td><td>0.0004</td><td>1.467</td><td>0.05</td><td>0.043</td><td>19.097</td><td>0.021</td><td>0.016</td><td>2.042</td><td>0.006</td><td>0.007</td><td>0.0002971</td><td>0.016</td><td>0.008</td><td>3.538</td><td>0.079</td><td>-0.077</td><td>0.382</td><td>0.069</td><td>...</td><td>3.451437393358561</td></tr>\n",
       "<tr><td>1163359</td><td>2M19255838+3650557</td><td>4571.9</td><td>71.0</td><td>-0.339</td><td>0.032</td><td>0.218</td><td>0.017</td><td>21.468</td><td>0.009</td><td>2.632</td><td>0.009</td><td>RGB</td><td>1.0346</td><td>0.0005</td><td>1.454</td><td>0.051</td><td>0.043</td><td>15.297</td><td>0.022</td><td>0.016</td><td>2.231</td><td>0.005</td><td>0.007</td><td>0.0005725</td><td>0.018</td><td>0.008</td><td>3.376</td><td>0.075</td><td>-0.072</td><td>0.195</td><td>0.076</td><td>...</td><td>2.3768402866248763</td></tr>\n",
       "<tr><td>1163621</td><td>2M19261297+3648265</td><td>4933.2</td><td>84.7</td><td>0.028</td><td>0.033</td><td>0.005</td><td>0.012</td><td>50.714</td><td>0.009</td><td>5.004</td><td>0.004</td><td>RC</td><td>1.0012</td><td>0.0331</td><td>1.876</td><td>0.138</td><td>0.07</td><td>11.092</td><td>0.068</td><td>0.019</td><td>2.621</td><td>0.005</td><td>0.009</td><td>0.001938</td><td>0.067</td><td>0.008</td><td>3.142</td><td>0.121</td><td>-0.108</td><td>0.422</td><td>0.08</td><td>...</td><td>1.386755828871888</td></tr>\n",
       "<tr><td>1294122</td><td>2M19250718+3654252</td><td>4803.1</td><td>75.0</td><td>-0.009</td><td>0.031</td><td>0.005</td><td>0.012</td><td>75.309</td><td>0.009</td><td>7.032</td><td>0.004</td><td>RGB</td><td>1.0292</td><td>0.0003</td><td>1.355</td><td>0.039</td><td>0.038</td><td>7.789</td><td>0.014</td><td>0.014</td><td>2.787</td><td>0.005</td><td>0.007</td><td>0.004044</td><td>0.008</td><td>0.007</td><td>3.559</td><td>0.06</td><td>-0.059</td><td>0.237</td><td>0.074</td><td>...</td><td>3.622429984166988</td></tr>\n",
       "<tr><td>1294385</td><td>2M19252149+3654097</td><td>4818.8</td><td>75.5</td><td>0.106</td><td>0.03</td><td>-0.011</td><td>0.011</td><td>106.469</td><td>0.009</td><td>9.116</td><td>0.004</td><td>RGB</td><td>1.0253</td><td>0.0004</td><td>1.383</td><td>0.039</td><td>0.036</td><td>6.613</td><td>0.014</td><td>0.013</td><td>2.938</td><td>0.005</td><td>0.007</td><td>0.006745</td><td>0.008</td><td>0.007</td><td>3.568</td><td>0.062</td><td>-0.059</td><td>0.07</td><td>0.074</td><td>...</td><td>3.6982817978026628</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>12688798</td><td>2M19145446+5152345</td><td>4199.1</td><td>53.8</td><td>0.315</td><td>0.019</td><td>0.032</td><td>0.01</td><td>14.131</td><td>0.044</td><td>1.987</td><td>0.011</td><td>RGB</td><td>1.0478</td><td>0.0004</td><td>1.068</td><td>0.14</td><td>0.043</td><td>16.508</td><td>0.05</td><td>0.016</td><td>2.031</td><td>0.019</td><td>0.007</td><td>0.0003347</td><td>0.022</td><td>0.008</td><td>4.02</td><td>0.218</td><td>-0.201</td><td>0.16</td><td>0.074</td><td>...</td><td>10.471285480508985</td></tr>\n",
       "<tr><td>12689506</td><td>2M19163834+5151526</td><td>4937.3</td><td>92.4</td><td>-0.333</td><td>0.039</td><td>0.218</td><td>0.017</td><td>37.241</td><td>0.009</td><td>4.204</td><td>0.039</td><td>RC(S)</td><td>0.9821</td><td>0.0488</td><td>1.612</td><td>0.255</td><td>0.076</td><td>11.997</td><td>0.127</td><td>0.022</td><td>2.487</td><td>0.006</td><td>0.01</td><td>0.001316</td><td>0.126</td><td>0.008</td><td>3.195</td><td>0.336</td><td>-0.18</td><td>0.239</td><td>0.532</td><td>SeisUnc</td><td>1.5667510701081484</td></tr>\n",
       "<tr><td>12690461</td><td>2M19184851+5152079</td><td>4749.8</td><td>77.1</td><td>-0.24</td><td>0.034</td><td>0.191</td><td>0.015</td><td>28.244</td><td>0.03</td><td>3.888</td><td>0.018</td><td>RC</td><td>0.9935</td><td>0.013</td><td>0.867</td><td>0.13</td><td>0.08</td><td>10.199</td><td>0.055</td><td>0.024</td><td>2.359</td><td>0.013</td><td>0.01</td><td>0.001152</td><td>0.045</td><td>0.008</td><td>3.894</td><td>0.121</td><td>-0.122</td><td>0.16</td><td>0.079</td><td>...</td><td>7.834296427662119</td></tr>\n",
       "<tr><td>12735106</td><td>2M19172948+5156326</td><td>4648.1</td><td>67.9</td><td>0.193</td><td>0.026</td><td>0.02</td><td>0.01</td><td>33.407</td><td>0.018</td><td>4.049</td><td>0.016</td><td>RC</td><td>1.0033</td><td>0.0073</td><td>1.135</td><td>0.09</td><td>0.078</td><td>10.79</td><td>0.04</td><td>0.023</td><td>2.427</td><td>0.008</td><td>0.01</td><td>0.001274</td><td>0.035</td><td>0.008</td><td>3.711</td><td>0.096</td><td>-0.088</td><td>0.202</td><td>0.073</td><td>...</td><td>5.140436515824259</td></tr>\n",
       "<tr><td>12735291</td><td>2M19175256+5154430</td><td>4718.4</td><td>82.0</td><td>-0.088</td><td>0.03</td><td>0.106</td><td>0.014</td><td>30.239</td><td>0.009</td><td>3.996</td><td>0.012</td><td>RC</td><td>0.9992</td><td>0.0092</td><td>0.922</td><td>0.07</td><td>0.079</td><td>10.186</td><td>0.032</td><td>0.024</td><td>2.387</td><td>0.006</td><td>0.01</td><td>0.001231</td><td>0.03</td><td>0.008</td><td>3.869</td><td>0.068</td><td>-0.07</td><td>0.152</td><td>0.084</td><td>...</td><td>7.396052750582382</td></tr>\n",
       "<tr><td>12735851</td><td>2M19192010+5158343</td><td>4706.3</td><td>71.7</td><td>-0.25</td><td>0.034</td><td>0.065</td><td>0.015</td><td>42.809</td><td>0.009</td><td>4.775</td><td>0.006</td><td>RGB</td><td>1.0371</td><td>0.001</td><td>1.101</td><td>0.043</td><td>0.041</td><td>9.36</td><td>0.017</td><td>0.015</td><td>2.537</td><td>0.005</td><td>0.007</td><td>0.001893</td><td>0.012</td><td>0.007</td><td>3.805</td><td>0.069</td><td>-0.065</td><td>0.165</td><td>0.073</td><td>...</td><td>6.382634861905489</td></tr>\n",
       "<tr><td>12736410</td><td>2M19203116+5156352</td><td>4800.7</td><td>75.0</td><td>-0.042</td><td>0.032</td><td>0.044</td><td>0.013</td><td>32.015</td><td>0.012</td><td>3.956</td><td>0.017</td><td>RC</td><td>0.9963</td><td>0.0225</td><td>1.183</td><td>0.12</td><td>0.078</td><td>11.163</td><td>0.058</td><td>0.023</td><td>2.415</td><td>0.006</td><td>0.01</td><td>0.001199</td><td>0.056</td><td>0.008</td><td>3.616</td><td>0.133</td><td>-0.128</td><td>0.241</td><td>0.076</td><td>...</td><td>4.130475019901614</td></tr>\n",
       "<tr><td>12784948</td><td>2M19210624+5200236</td><td>4956.6</td><td>83.2</td><td>-0.381</td><td>0.042</td><td>0.092</td><td>0.016</td><td>34.03</td><td>0.009</td><td>4.17</td><td>0.015</td><td>RC</td><td>0.9867</td><td>0.0219</td><td>1.254</td><td>0.114</td><td>0.077</td><td>11.061</td><td>0.055</td><td>0.023</td><td>2.449</td><td>0.005</td><td>0.01</td><td>0.001307</td><td>0.054</td><td>0.008</td><td>3.476</td><td>0.143</td><td>-0.127</td><td>0.217</td><td>0.079</td><td>...</td><td>2.992264636608189</td></tr>\n",
       "<tr><td>12785083</td><td>2M19212376+5204593</td><td>4689.1</td><td>70.0</td><td>-0.001</td><td>0.029</td><td>0.083</td><td>0.012</td><td>28.558</td><td>0.019</td><td>3.618</td><td>0.016</td><td>RC</td><td>0.9973</td><td>0.0399</td><td>1.154</td><td>0.183</td><td>0.08</td><td>11.742</td><td>0.088</td><td>0.024</td><td>2.361</td><td>0.009</td><td>0.01</td><td>0.001005</td><td>0.086</td><td>0.008</td><td>3.645</td><td>0.207</td><td>-0.192</td><td>0.17</td><td>0.074</td><td>...</td><td>4.4157044735331255</td></tr>\n",
       "<tr><td>12785250</td><td>2M19214766+5205365</td><td>4764.1</td><td>85.4</td><td>-0.312</td><td>0.035</td><td>0.031</td><td>0.017</td><td>32.908</td><td>0.015</td><td>3.85</td><td>0.004</td><td>RC(S)</td><td>1.0015</td><td>0.0216</td><td>1.386</td><td>0.102</td><td>0.078</td><td>11.942</td><td>0.047</td><td>0.023</td><td>2.426</td><td>0.008</td><td>0.01</td><td>0.001148</td><td>0.044</td><td>0.008</td><td>3.368</td><td>0.128</td><td>-0.113</td><td>0.272</td><td>0.085</td><td>...</td><td>2.3334580622810024</td></tr>\n",
       "<tr><td>12884116</td><td>2M19182431+5215519</td><td>4642.0</td><td>68.0</td><td>0.008</td><td>0.028</td><td>0.047</td><td>0.012</td><td>50.54</td><td>0.009</td><td>5.402</td><td>0.004</td><td>RGB</td><td>1.0378</td><td>0.001</td><td>1.081</td><td>0.039</td><td>0.04</td><td>8.563</td><td>0.014</td><td>0.015</td><td>2.606</td><td>0.005</td><td>0.007</td><td>0.002427</td><td>0.008</td><td>0.007</td><td>3.935</td><td>0.066</td><td>-0.064</td><td>0.303</td><td>0.071</td><td>...</td><td>8.609937521846009</td></tr>\n",
       "<tr><td>12884930</td><td>2M19200187+5214588</td><td>4913.6</td><td>89.4</td><td>-0.079</td><td>0.034</td><td>0.011</td><td>0.014</td><td>37.999</td><td>0.009</td><td>4.385</td><td>0.015</td><td>RC</td><td>0.9988</td><td>0.0114</td><td>1.343</td><td>0.086</td><td>0.075</td><td>10.854</td><td>0.041</td><td>0.022</td><td>2.495</td><td>0.006</td><td>0.01</td><td>0.001481</td><td>0.038</td><td>0.008</td><td>3.469</td><td>0.097</td><td>-0.103</td><td>0.315</td><td>0.086</td><td>...</td><td>2.9444216337987603</td></tr>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=6529>\n",
       "  KIC          2MASS          Teff   e_Teff   FeH     e_FeH   ... e_LogAge    Av     e_Av   Notes         Age        \n",
       "                               K       K    dex(---) dex(---) ...   Myr      mag     mag                             \n",
       " int64         str18        float64 float64 float64  float64  ... float64  float64 float64  str18       float64      \n",
       "-------- ------------------ ------- ------- -------- -------- ... -------- ------- ------- ------- ------------------\n",
       " 1027110 2M19250937+3644599  4177.6    51.8   -0.232    0.025 ...   -0.189   0.269   0.121 SeisUnc 10.046157902783946\n",
       " 1027337 2M19252021+3647118  4636.0    67.3    0.275    0.024 ...    -0.09   0.214   0.071     ... 6.2805835881331795\n",
       " 1160789 2M19233280+3652207  4729.6    72.3   -0.257    0.034 ...   -0.146   0.009   0.074     ...  7.744617978025183\n",
       " 1161447 2M19241746+3651460  4776.1    86.2    0.058    0.029 ...   -0.145     0.4   0.086     ...   2.48885731828239\n",
       " 1161618 2M19242614+3648478  4742.0    72.1    0.064    0.029 ...   -0.069   0.199   0.074     ...  4.355118736855684\n",
       " 1162220 2M19245791+3653298  4190.1    51.7    0.083    0.021 ...   -0.083   0.181   0.073     ...  11.37627285823431\n",
       " 1162746 2M19252639+3649116  4798.1    75.6   -0.388    0.038 ...   -0.131   0.172   0.075     ...  6.109420249055721\n",
       " 1163114 2M19254564+3650475  4285.8    54.4    0.297     0.02 ...   -0.077   0.382   0.069     ...  3.451437393358561\n",
       " 1163359 2M19255838+3650557  4571.9    71.0   -0.339    0.032 ...   -0.072   0.195   0.076     ... 2.3768402866248763\n",
       " 1163621 2M19261297+3648265  4933.2    84.7    0.028    0.033 ...   -0.108   0.422    0.08     ...  1.386755828871888\n",
       " 1294122 2M19250718+3654252  4803.1    75.0   -0.009    0.031 ...   -0.059   0.237   0.074     ...  3.622429984166988\n",
       " 1294385 2M19252149+3654097  4818.8    75.5    0.106     0.03 ...   -0.059    0.07   0.074     ... 3.6982817978026628\n",
       "     ...                ...     ...     ...      ...      ... ...      ...     ...     ...     ...                ...\n",
       "12688798 2M19145446+5152345  4199.1    53.8    0.315    0.019 ...   -0.201    0.16   0.074     ... 10.471285480508985\n",
       "12689506 2M19163834+5151526  4937.3    92.4   -0.333    0.039 ...    -0.18   0.239   0.532 SeisUnc 1.5667510701081484\n",
       "12690461 2M19184851+5152079  4749.8    77.1    -0.24    0.034 ...   -0.122    0.16   0.079     ...  7.834296427662119\n",
       "12735106 2M19172948+5156326  4648.1    67.9    0.193    0.026 ...   -0.088   0.202   0.073     ...  5.140436515824259\n",
       "12735291 2M19175256+5154430  4718.4    82.0   -0.088     0.03 ...    -0.07   0.152   0.084     ...  7.396052750582382\n",
       "12735851 2M19192010+5158343  4706.3    71.7    -0.25    0.034 ...   -0.065   0.165   0.073     ...  6.382634861905489\n",
       "12736410 2M19203116+5156352  4800.7    75.0   -0.042    0.032 ...   -0.128   0.241   0.076     ...  4.130475019901614\n",
       "12784948 2M19210624+5200236  4956.6    83.2   -0.381    0.042 ...   -0.127   0.217   0.079     ...  2.992264636608189\n",
       "12785083 2M19212376+5204593  4689.1    70.0   -0.001    0.029 ...   -0.192    0.17   0.074     ... 4.4157044735331255\n",
       "12785250 2M19214766+5205365  4764.1    85.4   -0.312    0.035 ...   -0.113   0.272   0.085     ... 2.3334580622810024\n",
       "12884116 2M19182431+5215519  4642.0    68.0    0.008    0.028 ...   -0.064   0.303   0.071     ...  8.609937521846009\n",
       "12884930 2M19200187+5214588  4913.6    89.4   -0.079    0.034 ...   -0.103   0.315   0.086     ... 2.9444216337987603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age option 2 APOKASC-2 Pinsonneault et al. 2018\n",
    "#Reading in the table, making sure all the tables have a column named Age in Gyr\n",
    "# and that every star in the table has an Age\n",
    "apokasc2raw = Table.read(\"Pinsonneault2018.txt\", format=\"ascii.cds\")\n",
    "apokasc2raw['Age']=(10**np.array(apokasc2raw['LogAge'])/1000.) #Age was in log(Myr) so needs converting\n",
    "hasagea2=np.where((apokasc2raw['Age']==apokasc2raw['Age']) & (apokasc2raw['Age']>0.1))\n",
    "apokasc2=apokasc2raw[hasagea2]\n",
    "apokasc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842af861-cd4a-4cd8-8516-8a813f1531be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Age option 3 APOKASC-3 Pinsonneault et al. 2025\n",
    "# #Reading in the table, making sure all the tables have a column named Age in Gyr\n",
    "# # and that every star in the table has an Age\n",
    "# apokasc3raw= Table.read(\"Pinsonneault2025.txt\", format=\"ascii.cds\")\n",
    "# #in this case there were two age columns, one for Red Clump and one for Red Giant Branch so we combine them\n",
    "# ageRC=np.array(apokasc3raw['AgeRC']*(apokasc3raw['EvolState']=='RC'))\n",
    "# rcnans=np.isnan(ageRC) #removing nans from this version of the table.\n",
    "# ageRC[rcnans]=0\n",
    "# ageRGB=np.array(apokasc3raw['AgeRGB']*(apokasc3raw['EvolState']=='RGB'))\n",
    "# rgbnans=np.isnan(ageRGB) #removing nans from this version of the table.\n",
    "# ageRGB[rgbnans]=0\n",
    "# apokasc3raw['Age']=(ageRC+ageRGB)\n",
    "\n",
    "# hasagea3=np.where((apokasc3raw['Age']==apokasc3raw['Age']) & (apokasc3raw['Age']>0.1))\n",
    "# apokasc3=apokasc3raw[hasagea3]\n",
    "# apokasc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4214dd6-940b-4f89-9091-e33337955724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Age option 4 K2 data Warfield et al. 2024\n",
    "# #Reading in the table, making sure all the tables have a column named Age in Gyr\n",
    "# # and that every star in the table has an Age\n",
    "# apok2raw = Table.read(\"Warfield2024.txt\", format=\"ascii.cds\")\n",
    "# #this one has an age column in Gyr already so we're just going to rename it Age\n",
    "# hasageapok2=np.where((apok2raw['Age']==apok2raw['Age']) & (apok2raw['Age']>0.1))\n",
    "# apok2=apok2raw[hasageapok2]\n",
    "# apok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "135c6c2b-b3f4-48e8-b50b-a07883191546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My initial pick for training set\n",
    "agedata= apokasc2\n",
    "agedata2= tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f927d0ef-3328-443f-9d1d-683402672d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5993 15517\n"
     ]
    }
   ],
   "source": [
    "#Option 1 TESS Theodoridis et al. 2025\n",
    "intersect2, ind_a2, ind_b2 = np.intersect1d(data_masked['tic_v8_id'],agedata2['TIC'], return_indices=True)\n",
    "\n",
    "#Option 2 APOKASC-2 Pinsonneault et al. 2018\n",
    "intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['2MASS'], return_indices=True) \n",
    "\n",
    "#Option 3 APOKASC-3 Pinsonneault et al. 2025\n",
    "#intersect, ind_a, ind_b = np.intersect1d(data_masked['gaia_dr3_source_id'],agedata['GaiaDR3'], return_indices=True) \n",
    "\n",
    "#Option 4 APO-K2 Warfield et al. 2024\n",
    "#intersect, ind_a, ind_b = np.intersect1d(data_masked['sdss4_apogee_id'],agedata['APOGEE'], return_indices=True) \n",
    "\n",
    "print(len(ind_b), len(ind_b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be3eb51-5d32-448b-a392-89487b460ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a705e5-d564-47dd-84ec-e4192228caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d1412-8db3-45b1-b697-20eec53a4b6c",
   "metadata": {},
   "source": [
    "## First Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a67d4f1a-b90f-4121-a81b-afd299661f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullx = np.dstack([data_masked['teff'][ind_a],data_masked['logg'][ind_a], data_masked['m_h_atm'][ind_a],\n",
    "                   data_masked['alpha_m_atm'][ind_a], data_masked['c_h'][ind_a], data_masked['n_h'][ind_a]])[0]\n",
    "\n",
    "fully = np.dstack([agedata['Age'][ind_b]])[0] #for Pinsonneault 2018\n",
    "\n",
    "#remove non-finite entries!\n",
    "mask = np.all(np.isfinite(fullx), axis=1) & np.all(np.isfinite(fully), axis=1)\n",
    "fullx, fully = fullx[mask], fully[mask]\n",
    "\n",
    "scaling_x = np.median(fullx, axis=0)\n",
    "scaling_y = np.median(fully, axis=0)\n",
    "\n",
    "fullx, fully = fullx/scaling_x, fully/scaling_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d16572b8-0b68-48aa-8154-52134dea03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_per_layer=20\n",
    "layers=5\n",
    "iterations=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02a8d619-e578-425a-aa24-feb2e5b705a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"test\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"test\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m140\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m420\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m420\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m420\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m21\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421</span> (5.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,421\u001b[0m (5.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421</span> (5.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,421\u001b[0m (5.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#start with an input layer\n",
    "inputs = keras.Input(shape=(6,))\n",
    "#now we add the Dense layers (indicating the previous layer in the brackets following the layer declaration\n",
    "\n",
    "#change this part if you're changing the number of layers\n",
    "layer1 =keras.layers.Dense(neurons_per_layer, activation='relu')(inputs)\n",
    "layer2 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer1)\n",
    "layer3 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer2)\n",
    "layer4 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer3)\n",
    "layer5 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer4)\n",
    "layer6 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer5)\n",
    "layer7 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer6)\n",
    "layer8 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer7)\n",
    "layer9 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer8)\n",
    "layer10 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer9)\n",
    "layer11 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer10)\n",
    "layer12 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer11)\n",
    "layer13 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer12)\n",
    "layer14 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer13)\n",
    "layer15 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer14)\n",
    "layer16 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer15)\n",
    "layer17 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer16)\n",
    "layer18 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer17)\n",
    "layer19 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer18)\n",
    "layer20 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer19)\n",
    "layer21 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer20)\n",
    "layer22 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer21)\n",
    "layer23 = keras.layers.Dense(neurons_per_layer, activation='relu')(layer22)\n",
    "\n",
    "#then the output layer YOU ALSO HAVE TO MAKE THIS MATCH YOUR NUMBER OF LAYERS\n",
    "outputs = keras.layers.Dense(1)(layer4)\n",
    "\n",
    "\n",
    "# then we put that all together in the Model object\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='test')\n",
    "#and we can print a summary to check it all went to plan\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b49f6c53-d915-4af4-9a1b-9fe2151140ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dbbfa16-1d2c-4204-9cbd-592fcb53d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenpercent=len(agedata['Age'][ind_b])//10 #figure out what ten percent of this set of age data is\n",
    "\n",
    "#last name before M \n",
    "#trainbin=slice(0,-1*tenpercent-1)\n",
    "#testing=slice(-1*tenpercent,-1)\n",
    "\n",
    "\n",
    "#last name M or later\n",
    "trainbin=slice(tenpercent+1,-1)\n",
    "testing=slice(0,tenpercent)\n",
    "\n",
    "\n",
    "x_train, y_train = fullx[trainbin], fully[trainbin]\n",
    "x_test, y_test = fullx[testing], fully[testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed78eb61-fae5-4e7c-a84b-5a149a9e2486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 2.0354e-04 - loss: 1.5948 - val_accuracy: 0.0000e+00 - val_loss: 0.8921\n",
      "Epoch 2/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 6.1062e-04 - loss: 0.8438 - val_accuracy: 0.0000e+00 - val_loss: 0.6532\n",
      "Epoch 3/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 6.1062e-04 - loss: 0.6393 - val_accuracy: 0.0000e+00 - val_loss: 0.5009\n",
      "Epoch 4/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0010 - loss: 0.4901 - val_accuracy: 0.0000e+00 - val_loss: 0.3903\n",
      "Epoch 5/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.3868 - val_accuracy: 0.0039 - val_loss: 0.3205\n",
      "Epoch 6/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.3333 - val_accuracy: 0.0039 - val_loss: 0.2794\n",
      "Epoch 7/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2991 - val_accuracy: 0.0039 - val_loss: 0.2503\n",
      "Epoch 8/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2753 - val_accuracy: 0.0039 - val_loss: 0.2396\n",
      "Epoch 9/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.2633 - val_accuracy: 0.0039 - val_loss: 0.2343\n",
      "Epoch 10/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2565 - val_accuracy: 0.0039 - val_loss: 0.2292\n",
      "Epoch 11/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0012 - loss: 0.2521 - val_accuracy: 0.0039 - val_loss: 0.2266\n",
      "Epoch 12/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2475 - val_accuracy: 0.0039 - val_loss: 0.2268\n",
      "Epoch 13/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2454 - val_accuracy: 0.0039 - val_loss: 0.2276\n",
      "Epoch 14/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2424 - val_accuracy: 0.0039 - val_loss: 0.2239\n",
      "Epoch 15/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.2406 - val_accuracy: 0.0039 - val_loss: 0.2242\n",
      "Epoch 16/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2421 - val_accuracy: 0.0039 - val_loss: 0.2254\n",
      "Epoch 17/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2446 - val_accuracy: 0.0039 - val_loss: 0.2276\n",
      "Epoch 18/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2388 - val_accuracy: 0.0039 - val_loss: 0.2308\n",
      "Epoch 19/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.2386 - val_accuracy: 0.0039 - val_loss: 0.2223\n",
      "Epoch 20/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2367 - val_accuracy: 0.0039 - val_loss: 0.2185\n",
      "Epoch 21/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2335 - val_accuracy: 0.0039 - val_loss: 0.2172\n",
      "Epoch 22/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2314 - val_accuracy: 0.0039 - val_loss: 0.2175\n",
      "Epoch 23/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2302 - val_accuracy: 0.0039 - val_loss: 0.2160\n",
      "Epoch 24/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2306 - val_accuracy: 0.0039 - val_loss: 0.2159\n",
      "Epoch 25/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2337 - val_accuracy: 0.0039 - val_loss: 0.2150\n",
      "Epoch 26/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2264 - val_accuracy: 0.0039 - val_loss: 0.2187\n",
      "Epoch 27/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2289 - val_accuracy: 0.0039 - val_loss: 0.2151\n",
      "Epoch 28/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2300 - val_accuracy: 0.0039 - val_loss: 0.2118\n",
      "Epoch 29/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2269 - val_accuracy: 0.0039 - val_loss: 0.2212\n",
      "Epoch 30/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2271 - val_accuracy: 0.0039 - val_loss: 0.2143\n",
      "Epoch 31/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2256 - val_accuracy: 0.0039 - val_loss: 0.2116\n",
      "Epoch 32/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0012 - loss: 0.2268 - val_accuracy: 0.0039 - val_loss: 0.2125\n",
      "Epoch 33/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2248 - val_accuracy: 0.0039 - val_loss: 0.2192\n",
      "Epoch 34/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2267 - val_accuracy: 0.0039 - val_loss: 0.2095\n",
      "Epoch 35/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2271 - val_accuracy: 0.0039 - val_loss: 0.2099\n",
      "Epoch 36/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2245 - val_accuracy: 0.0039 - val_loss: 0.2098\n",
      "Epoch 37/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2218 - val_accuracy: 0.0039 - val_loss: 0.2063\n",
      "Epoch 38/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2200 - val_accuracy: 0.0039 - val_loss: 0.2116\n",
      "Epoch 39/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0012 - loss: 0.2194 - val_accuracy: 0.0039 - val_loss: 0.2076\n",
      "Epoch 40/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2189 - val_accuracy: 0.0039 - val_loss: 0.2059\n",
      "Epoch 41/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2199 - val_accuracy: 0.0039 - val_loss: 0.2041\n",
      "Epoch 42/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2194 - val_accuracy: 0.0039 - val_loss: 0.2062\n",
      "Epoch 43/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2202 - val_accuracy: 0.0039 - val_loss: 0.2041\n",
      "Epoch 44/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2174 - val_accuracy: 0.0039 - val_loss: 0.2049\n",
      "Epoch 45/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2177 - val_accuracy: 0.0039 - val_loss: 0.2013\n",
      "Epoch 46/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2199 - val_accuracy: 0.0039 - val_loss: 0.2058\n",
      "Epoch 47/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2150 - val_accuracy: 0.0039 - val_loss: 0.2056\n",
      "Epoch 48/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2153 - val_accuracy: 0.0039 - val_loss: 0.2044\n",
      "Epoch 49/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0012 - loss: 0.2156 - val_accuracy: 0.0039 - val_loss: 0.2050\n",
      "Epoch 50/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2150 - val_accuracy: 0.0039 - val_loss: 0.2003\n",
      "Epoch 51/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2133 - val_accuracy: 0.0039 - val_loss: 0.2004\n",
      "Epoch 52/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2140 - val_accuracy: 0.0039 - val_loss: 0.2005\n",
      "Epoch 53/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2140 - val_accuracy: 0.0039 - val_loss: 0.1994\n",
      "Epoch 54/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2133 - val_accuracy: 0.0039 - val_loss: 0.1981\n",
      "Epoch 55/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0012 - loss: 0.2143 - val_accuracy: 0.0039 - val_loss: 0.1978\n",
      "Epoch 56/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2118 - val_accuracy: 0.0039 - val_loss: 0.1990\n",
      "Epoch 57/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2110 - val_accuracy: 0.0039 - val_loss: 0.2037\n",
      "Epoch 58/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2142 - val_accuracy: 0.0039 - val_loss: 0.1986\n",
      "Epoch 59/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2121 - val_accuracy: 0.0000e+00 - val_loss: 0.1964\n",
      "Epoch 60/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.2108 - val_accuracy: 0.0039 - val_loss: 0.1957\n",
      "Epoch 61/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2081 - val_accuracy: 0.0039 - val_loss: 0.1945\n",
      "Epoch 62/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2093 - val_accuracy: 0.0039 - val_loss: 0.1940\n",
      "Epoch 63/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2083 - val_accuracy: 0.0000e+00 - val_loss: 0.2007\n",
      "Epoch 64/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2078 - val_accuracy: 0.0000e+00 - val_loss: 0.1917\n",
      "Epoch 65/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0012 - loss: 0.2074 - val_accuracy: 0.0039 - val_loss: 0.1924\n",
      "Epoch 66/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0012 - loss: 0.2087 - val_accuracy: 0.0000e+00 - val_loss: 0.1960\n",
      "Epoch 67/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.2064 - val_accuracy: 0.0000e+00 - val_loss: 0.1902\n",
      "Epoch 68/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.2061 - val_accuracy: 0.0000e+00 - val_loss: 0.1991\n",
      "Epoch 69/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.2051 - val_accuracy: 0.0039 - val_loss: 0.1944\n",
      "Epoch 70/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0012 - loss: 0.2052 - val_accuracy: 0.0000e+00 - val_loss: 0.1963\n",
      "Epoch 71/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.2039 - val_accuracy: 0.0039 - val_loss: 0.1886\n",
      "Epoch 72/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2045 - val_accuracy: 0.0000e+00 - val_loss: 0.1895\n",
      "Epoch 73/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.2077 - val_accuracy: 0.0000e+00 - val_loss: 0.1996\n",
      "Epoch 74/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.2069 - val_accuracy: 0.0000e+00 - val_loss: 0.1914\n",
      "Epoch 75/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2064 - val_accuracy: 0.0000e+00 - val_loss: 0.1928\n",
      "Epoch 76/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0012 - loss: 0.2029 - val_accuracy: 0.0000e+00 - val_loss: 0.1963\n",
      "Epoch 77/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0012 - loss: 0.2009 - val_accuracy: 0.0000e+00 - val_loss: 0.1883\n",
      "Epoch 78/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.0012 - loss: 0.2026 - val_accuracy: 0.0000e+00 - val_loss: 0.1881\n",
      "Epoch 79/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.0012 - loss: 0.2034 - val_accuracy: 0.0000e+00 - val_loss: 0.1878\n",
      "Epoch 80/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0012 - loss: 0.2009 - val_accuracy: 0.0000e+00 - val_loss: 0.1952\n",
      "Epoch 81/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0012 - loss: 0.2023 - val_accuracy: 0.0000e+00 - val_loss: 0.1924\n",
      "Epoch 82/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0012 - loss: 0.2006 - val_accuracy: 0.0039 - val_loss: 0.1858\n",
      "Epoch 83/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0012 - loss: 0.2033 - val_accuracy: 0.0039 - val_loss: 0.1870\n",
      "Epoch 84/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0012 - loss: 0.2085 - val_accuracy: 0.0000e+00 - val_loss: 0.1952\n",
      "Epoch 85/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0012 - loss: 0.1997 - val_accuracy: 0.0000e+00 - val_loss: 0.1869\n",
      "Epoch 86/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.0012 - loss: 0.1991 - val_accuracy: 0.0000e+00 - val_loss: 0.1853\n",
      "Epoch 87/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0012 - loss: 0.2010 - val_accuracy: 0.0039 - val_loss: 0.1910\n",
      "Epoch 88/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0012 - loss: 0.1983 - val_accuracy: 0.0000e+00 - val_loss: 0.1867\n",
      "Epoch 89/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0012 - loss: 0.1987 - val_accuracy: 0.0000e+00 - val_loss: 0.1896\n",
      "Epoch 90/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1967 - val_accuracy: 0.0000e+00 - val_loss: 0.1912\n",
      "Epoch 91/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1975 - val_accuracy: 0.0000e+00 - val_loss: 0.1882\n",
      "Epoch 92/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0012 - loss: 0.1957 - val_accuracy: 0.0000e+00 - val_loss: 0.1893\n",
      "Epoch 93/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1964 - val_accuracy: 0.0039 - val_loss: 0.1915\n",
      "Epoch 94/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1960 - val_accuracy: 0.0000e+00 - val_loss: 0.1956\n",
      "Epoch 95/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1971 - val_accuracy: 0.0039 - val_loss: 0.1815\n",
      "Epoch 96/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1966 - val_accuracy: 0.0000e+00 - val_loss: 0.1844\n",
      "Epoch 97/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1957 - val_accuracy: 0.0039 - val_loss: 0.1904\n",
      "Epoch 98/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1960 - val_accuracy: 0.0000e+00 - val_loss: 0.1843\n",
      "Epoch 99/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1953 - val_accuracy: 0.0039 - val_loss: 0.1842\n",
      "Epoch 100/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0012 - loss: 0.1957 - val_accuracy: 0.0000e+00 - val_loss: 0.1836\n",
      "Epoch 101/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0012 - loss: 0.1928 - val_accuracy: 0.0000e+00 - val_loss: 0.1824\n",
      "Epoch 102/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0012 - loss: 0.1922 - val_accuracy: 0.0000e+00 - val_loss: 0.1874\n",
      "Epoch 103/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1928 - val_accuracy: 0.0039 - val_loss: 0.1806\n",
      "Epoch 104/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1925 - val_accuracy: 0.0000e+00 - val_loss: 0.1837\n",
      "Epoch 105/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1905 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 106/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1925 - val_accuracy: 0.0000e+00 - val_loss: 0.1826\n",
      "Epoch 107/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0012 - loss: 0.2001 - val_accuracy: 0.0000e+00 - val_loss: 0.2068\n",
      "Epoch 108/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1990 - val_accuracy: 0.0000e+00 - val_loss: 0.1867\n",
      "Epoch 109/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1990 - val_accuracy: 0.0039 - val_loss: 0.1799\n",
      "Epoch 110/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.2000 - val_accuracy: 0.0039 - val_loss: 0.1789\n",
      "Epoch 111/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1942 - val_accuracy: 0.0000e+00 - val_loss: 0.1880\n",
      "Epoch 112/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1910 - val_accuracy: 0.0000e+00 - val_loss: 0.1944\n",
      "Epoch 113/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1907 - val_accuracy: 0.0000e+00 - val_loss: 0.1833\n",
      "Epoch 114/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1894 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
      "Epoch 115/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1907 - val_accuracy: 0.0000e+00 - val_loss: 0.1867\n",
      "Epoch 116/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1909 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
      "Epoch 117/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1897 - val_accuracy: 0.0039 - val_loss: 0.1823\n",
      "Epoch 118/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1925 - val_accuracy: 0.0000e+00 - val_loss: 0.1831\n",
      "Epoch 119/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1893 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
      "Epoch 120/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1963 - val_accuracy: 0.0039 - val_loss: 0.1800\n",
      "Epoch 121/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1973 - val_accuracy: 0.0039 - val_loss: 0.1785\n",
      "Epoch 122/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1954 - val_accuracy: 0.0000e+00 - val_loss: 0.1924\n",
      "Epoch 123/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1867 - val_accuracy: 0.0000e+00 - val_loss: 0.1823\n",
      "Epoch 124/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1867 - val_accuracy: 0.0000e+00 - val_loss: 0.1775\n",
      "Epoch 125/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1859 - val_accuracy: 0.0000e+00 - val_loss: 0.1749\n",
      "Epoch 126/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1883 - val_accuracy: 0.0000e+00 - val_loss: 0.1761\n",
      "Epoch 127/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1902 - val_accuracy: 0.0039 - val_loss: 0.1731\n",
      "Epoch 128/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.1909 - val_accuracy: 0.0039 - val_loss: 0.1768\n",
      "Epoch 129/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1886 - val_accuracy: 0.0000e+00 - val_loss: 0.1835\n",
      "Epoch 130/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1890 - val_accuracy: 0.0039 - val_loss: 0.1761\n",
      "Epoch 131/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1853 - val_accuracy: 0.0000e+00 - val_loss: 0.1843\n",
      "Epoch 132/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1843 - val_accuracy: 0.0039 - val_loss: 0.1749\n",
      "Epoch 133/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1865 - val_accuracy: 0.0039 - val_loss: 0.1742\n",
      "Epoch 134/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0012 - loss: 0.1918 - val_accuracy: 0.0039 - val_loss: 0.1783\n",
      "Epoch 135/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0012 - loss: 0.1845 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
      "Epoch 136/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1847 - val_accuracy: 0.0039 - val_loss: 0.1785\n",
      "Epoch 137/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1887 - val_accuracy: 0.0039 - val_loss: 0.1816\n",
      "Epoch 138/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1858 - val_accuracy: 0.0039 - val_loss: 0.1764\n",
      "Epoch 139/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1878 - val_accuracy: 0.0000e+00 - val_loss: 0.1837\n",
      "Epoch 140/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1848 - val_accuracy: 0.0039 - val_loss: 0.1741\n",
      "Epoch 141/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1836 - val_accuracy: 0.0039 - val_loss: 0.1814\n",
      "Epoch 142/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.0012 - loss: 0.1884 - val_accuracy: 0.0000e+00 - val_loss: 0.1933\n",
      "Epoch 143/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1895 - val_accuracy: 0.0039 - val_loss: 0.1875\n",
      "Epoch 144/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1962 - val_accuracy: 0.0039 - val_loss: 0.1688\n",
      "Epoch 145/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1900 - val_accuracy: 0.0039 - val_loss: 0.1736\n",
      "Epoch 146/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1788\n",
      "Epoch 147/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1832 - val_accuracy: 0.0039 - val_loss: 0.1786\n",
      "Epoch 148/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1826 - val_accuracy: 0.0000e+00 - val_loss: 0.1891\n",
      "Epoch 149/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0012 - loss: 0.1956 - val_accuracy: 0.0039 - val_loss: 0.1767\n",
      "Epoch 150/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1887 - val_accuracy: 0.0039 - val_loss: 0.1729\n",
      "Epoch 151/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1861 - val_accuracy: 0.0039 - val_loss: 0.1771\n",
      "Epoch 152/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0012 - loss: 0.1833 - val_accuracy: 0.0039 - val_loss: 0.1736\n",
      "Epoch 153/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1840 - val_accuracy: 0.0039 - val_loss: 0.1687\n",
      "Epoch 154/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1823 - val_accuracy: 0.0039 - val_loss: 0.1693\n",
      "Epoch 155/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1895 - val_accuracy: 0.0039 - val_loss: 0.1675\n",
      "Epoch 156/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1820 - val_accuracy: 0.0039 - val_loss: 0.1734\n",
      "Epoch 157/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1836 - val_accuracy: 0.0039 - val_loss: 0.1793\n",
      "Epoch 158/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1825 - val_accuracy: 0.0039 - val_loss: 0.1660\n",
      "Epoch 159/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1830 - val_accuracy: 0.0039 - val_loss: 0.1640\n",
      "Epoch 160/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1821 - val_accuracy: 0.0039 - val_loss: 0.1788\n",
      "Epoch 161/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1831 - val_accuracy: 0.0039 - val_loss: 0.1677\n",
      "Epoch 162/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0012 - loss: 0.1815 - val_accuracy: 0.0039 - val_loss: 0.1719\n",
      "Epoch 163/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1853 - val_accuracy: 0.0039 - val_loss: 0.1655\n",
      "Epoch 164/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1866 - val_accuracy: 0.0039 - val_loss: 0.1660\n",
      "Epoch 165/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1834 - val_accuracy: 0.0039 - val_loss: 0.1681\n",
      "Epoch 166/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.1793 - val_accuracy: 0.0039 - val_loss: 0.1745\n",
      "Epoch 167/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1799 - val_accuracy: 0.0039 - val_loss: 0.1694\n",
      "Epoch 168/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1795 - val_accuracy: 0.0039 - val_loss: 0.1696\n",
      "Epoch 169/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1812 - val_accuracy: 0.0039 - val_loss: 0.1689\n",
      "Epoch 170/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0012 - loss: 0.1779 - val_accuracy: 0.0039 - val_loss: 0.1626\n",
      "Epoch 171/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1812 - val_accuracy: 0.0039 - val_loss: 0.1699\n",
      "Epoch 172/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.1814 - val_accuracy: 0.0039 - val_loss: 0.1747\n",
      "Epoch 173/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0012 - loss: 0.1829 - val_accuracy: 0.0039 - val_loss: 0.1735\n",
      "Epoch 174/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1824 - val_accuracy: 0.0039 - val_loss: 0.1655\n",
      "Epoch 175/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1820 - val_accuracy: 0.0039 - val_loss: 0.1647\n",
      "Epoch 176/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.1781 - val_accuracy: 0.0039 - val_loss: 0.1681\n",
      "Epoch 177/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1790 - val_accuracy: 0.0039 - val_loss: 0.1635\n",
      "Epoch 178/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1781 - val_accuracy: 0.0039 - val_loss: 0.1621\n",
      "Epoch 179/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1803 - val_accuracy: 0.0039 - val_loss: 0.1729\n",
      "Epoch 180/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1779 - val_accuracy: 0.0039 - val_loss: 0.1666\n",
      "Epoch 181/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1768 - val_accuracy: 0.0039 - val_loss: 0.1703\n",
      "Epoch 182/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0012 - loss: 0.1788 - val_accuracy: 0.0039 - val_loss: 0.1594\n",
      "Epoch 183/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0012 - loss: 0.1778 - val_accuracy: 0.0039 - val_loss: 0.1756\n",
      "Epoch 184/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0012 - loss: 0.1796 - val_accuracy: 0.0039 - val_loss: 0.1830\n",
      "Epoch 185/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1816 - val_accuracy: 0.0039 - val_loss: 0.1608\n",
      "Epoch 186/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0012 - loss: 0.1794 - val_accuracy: 0.0039 - val_loss: 0.1610\n",
      "Epoch 187/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1795 - val_accuracy: 0.0039 - val_loss: 0.1620\n",
      "Epoch 188/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1807 - val_accuracy: 0.0039 - val_loss: 0.1594\n",
      "Epoch 189/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1767 - val_accuracy: 0.0039 - val_loss: 0.1607\n",
      "Epoch 190/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1744 - val_accuracy: 0.0039 - val_loss: 0.1609\n",
      "Epoch 191/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1804 - val_accuracy: 0.0039 - val_loss: 0.1665\n",
      "Epoch 192/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0012 - loss: 0.1844 - val_accuracy: 0.0039 - val_loss: 0.1641\n",
      "Epoch 193/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0012 - loss: 0.1733 - val_accuracy: 0.0039 - val_loss: 0.1577\n",
      "Epoch 194/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1832 - val_accuracy: 0.0039 - val_loss: 0.1613\n",
      "Epoch 195/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1766 - val_accuracy: 0.0039 - val_loss: 0.1662\n",
      "Epoch 196/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1770 - val_accuracy: 0.0039 - val_loss: 0.1641\n",
      "Epoch 197/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0012 - loss: 0.1789 - val_accuracy: 0.0039 - val_loss: 0.1604\n",
      "Epoch 198/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1797 - val_accuracy: 0.0039 - val_loss: 0.1592\n",
      "Epoch 199/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0012 - loss: 0.1734 - val_accuracy: 0.0039 - val_loss: 0.1738\n",
      "Epoch 200/200\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0012 - loss: 0.1780 - val_accuracy: 0.0039 - val_loss: 0.1599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d18e0321b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=iterations, validation_split=0.05, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9945274-b190-45b2-954c-5e681f461a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "599\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6133233a-176f-49b3-8768-75f30fc38369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425631\n",
      "\u001b[1m13301/13301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "DR19x = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
    "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
    "print(len(data_masked['teff']))\n",
    "\n",
    "DR19x= DR19x/scaling_x\n",
    "predictionsDR19 = model.predict(DR19x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799fc4d-9d03-422d-8658-825852967a4a",
   "metadata": {},
   "source": [
    "## Training Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82c3b69f-6967-45dd-ba85-0a09732fb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullx2 = np.dstack([data_masked['teff'][ind_a2],data_masked['logg'][ind_a2], data_masked['m_h_atm'][ind_a2],\n",
    "                   data_masked['alpha_m_atm'][ind_a2], data_masked['c_h'][ind_a2], data_masked['n_h'][ind_a2]])[0]\n",
    "\n",
    "fully2 = np.dstack([agedata2['Age'][ind_b2]])[0] #for Pinsonneault 2018\n",
    "\n",
    "#remove non-finite entries!\n",
    "mask2 = np.all(np.isfinite(fullx2), axis=1) & np.all(np.isfinite(fully2), axis=1)\n",
    "fullx2, fully2 = fullx2[mask2], fully2[mask2]\n",
    "\n",
    "scaling_x2 = np.median(fullx2, axis=0)\n",
    "scaling_y2 = np.median(fully2, axis=0)\n",
    "fullx2, fully2 = fullx2/scaling_x2, fully2/scaling_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15087510-3a8e-48a9-87c4-8d82826cfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenpercent2=len(agedata2['Age'][ind_b2])//10 #figure out what ten percent of this set of age data is\n",
    "\n",
    "#last name before M \n",
    "#trainbin=slice(0,-1*tenpercent-1)\n",
    "#testing=slice(-1*tenpercent,-1)\n",
    "\n",
    "\n",
    "#last name M or later\n",
    "trainbin2=slice(tenpercent2+1,-1)\n",
    "testing2=slice(0,tenpercent2)\n",
    "\n",
    "\n",
    "x_train2, y_train2 = fullx2[trainbin2], fully2[trainbin2]\n",
    "x_test2, y_test2 = fullx2[testing2], fully2[testing2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae47b020-77bc-4dc3-ad7c-9ff72cd1231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 7.9917e-05 - loss: 1.7490 - val_accuracy: 0.0000e+00 - val_loss: 0.2352\n",
      "Epoch 2/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.2340 - val_accuracy: 0.0000e+00 - val_loss: 0.1936\n",
      "Epoch 3/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.2043 - val_accuracy: 0.0000e+00 - val_loss: 0.1853\n",
      "Epoch 4/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1982 - val_accuracy: 0.0000e+00 - val_loss: 0.1831\n",
      "Epoch 5/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1948 - val_accuracy: 0.0000e+00 - val_loss: 0.1820\n",
      "Epoch 6/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1930 - val_accuracy: 0.0000e+00 - val_loss: 0.1824\n",
      "Epoch 7/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1915 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
      "Epoch 8/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1910 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
      "Epoch 9/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1903 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
      "Epoch 10/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1897 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
      "Epoch 11/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1896 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
      "Epoch 12/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1893 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
      "Epoch 13/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1887 - val_accuracy: 0.0000e+00 - val_loss: 0.1825\n",
      "Epoch 14/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1878 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
      "Epoch 15/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1874 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 16/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1879 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
      "Epoch 17/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1872 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 18/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 7.9917e-05 - loss: 0.1874 - val_accuracy: 0.0000e+00 - val_loss: 0.1818\n",
      "Epoch 19/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1867 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
      "Epoch 20/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1865 - val_accuracy: 0.0000e+00 - val_loss: 0.1797\n",
      "Epoch 21/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1866 - val_accuracy: 0.0000e+00 - val_loss: 0.1786\n",
      "Epoch 22/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.1788\n",
      "Epoch 23/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1862 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 24/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1858 - val_accuracy: 0.0000e+00 - val_loss: 0.1809\n",
      "Epoch 25/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1853 - val_accuracy: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 26/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1856 - val_accuracy: 0.0000e+00 - val_loss: 0.1784\n",
      "Epoch 27/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1851 - val_accuracy: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 28/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1850 - val_accuracy: 0.0000e+00 - val_loss: 0.1798\n",
      "Epoch 29/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1848 - val_accuracy: 0.0000e+00 - val_loss: 0.1778\n",
      "Epoch 30/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1852 - val_accuracy: 0.0000e+00 - val_loss: 0.1784\n",
      "Epoch 31/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1849 - val_accuracy: 0.0000e+00 - val_loss: 0.1784\n",
      "Epoch 32/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1851 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 33/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1851 - val_accuracy: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 34/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1860 - val_accuracy: 0.0000e+00 - val_loss: 0.1793\n",
      "Epoch 35/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1846 - val_accuracy: 0.0000e+00 - val_loss: 0.1798\n",
      "Epoch 36/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1845 - val_accuracy: 0.0000e+00 - val_loss: 0.1776\n",
      "Epoch 37/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1843 - val_accuracy: 0.0000e+00 - val_loss: 0.1782\n",
      "Epoch 38/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1843 - val_accuracy: 0.0000e+00 - val_loss: 0.1785\n",
      "Epoch 39/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1781\n",
      "Epoch 40/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1781\n",
      "Epoch 41/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1839 - val_accuracy: 0.0000e+00 - val_loss: 0.1781\n",
      "Epoch 42/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1842 - val_accuracy: 0.0000e+00 - val_loss: 0.1779\n",
      "Epoch 43/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1839 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 44/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1840 - val_accuracy: 0.0000e+00 - val_loss: 0.1786\n",
      "Epoch 45/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1833 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 46/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1832 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
      "Epoch 47/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1835 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 48/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1838 - val_accuracy: 0.0000e+00 - val_loss: 0.1781\n",
      "Epoch 49/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1828 - val_accuracy: 0.0000e+00 - val_loss: 0.1792\n",
      "Epoch 50/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1838 - val_accuracy: 0.0000e+00 - val_loss: 0.1779\n",
      "Epoch 51/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1841 - val_accuracy: 0.0000e+00 - val_loss: 0.1834\n",
      "Epoch 52/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1835 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
      "Epoch 53/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1829 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
      "Epoch 54/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1827 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
      "Epoch 55/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1825 - val_accuracy: 0.0000e+00 - val_loss: 0.1807\n",
      "Epoch 56/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1827 - val_accuracy: 0.0000e+00 - val_loss: 0.1781\n",
      "Epoch 57/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1821 - val_accuracy: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 58/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1828 - val_accuracy: 0.0000e+00 - val_loss: 0.1786\n",
      "Epoch 59/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1829 - val_accuracy: 0.0000e+00 - val_loss: 0.1793\n",
      "Epoch 60/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1828 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
      "Epoch 61/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1819 - val_accuracy: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 62/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1820 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
      "Epoch 63/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1798\n",
      "Epoch 64/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1825 - val_accuracy: 0.0000e+00 - val_loss: 0.1792\n",
      "Epoch 65/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1817 - val_accuracy: 0.0000e+00 - val_loss: 0.1797\n",
      "Epoch 66/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1817 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
      "Epoch 67/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
      "Epoch 68/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1823 - val_accuracy: 0.0000e+00 - val_loss: 0.1785\n",
      "Epoch 69/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1818 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 70/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1818 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
      "Epoch 71/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1815 - val_accuracy: 0.0000e+00 - val_loss: 0.1798\n",
      "Epoch 72/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1813 - val_accuracy: 0.0000e+00 - val_loss: 0.1793\n",
      "Epoch 73/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1814 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
      "Epoch 74/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1824 - val_accuracy: 0.0000e+00 - val_loss: 0.1840\n",
      "Epoch 75/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1819 - val_accuracy: 0.0000e+00 - val_loss: 0.1844\n",
      "Epoch 76/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 77/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1821 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
      "Epoch 78/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 79/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
      "Epoch 80/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1819 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
      "Epoch 81/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1816 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 82/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1817 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 83/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1814 - val_accuracy: 0.0000e+00 - val_loss: 0.1796\n",
      "Epoch 84/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1812 - val_accuracy: 0.0000e+00 - val_loss: 0.1830\n",
      "Epoch 85/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1832 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 86/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1809 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
      "Epoch 87/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1814 - val_accuracy: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 88/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1815 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
      "Epoch 89/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1792\n",
      "Epoch 90/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1828 - val_accuracy: 0.0000e+00 - val_loss: 0.1786\n",
      "Epoch 91/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1795\n",
      "Epoch 92/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1805 - val_accuracy: 0.0000e+00 - val_loss: 0.1801\n",
      "Epoch 93/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1809 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
      "Epoch 94/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1815 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
      "Epoch 95/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1821 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 96/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1810 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n",
      "Epoch 97/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1805 - val_accuracy: 0.0000e+00 - val_loss: 0.1779\n",
      "Epoch 98/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1804 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 99/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n",
      "Epoch 100/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1805 - val_accuracy: 0.0000e+00 - val_loss: 0.1799\n",
      "Epoch 101/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1785\n",
      "Epoch 102/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1803 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
      "Epoch 103/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1806 - val_accuracy: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 104/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1802 - val_accuracy: 0.0000e+00 - val_loss: 0.1814\n",
      "Epoch 105/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1798 - val_accuracy: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 106/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1805 - val_accuracy: 0.0000e+00 - val_loss: 0.1785\n",
      "Epoch 107/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1809 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 108/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1798 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 109/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1782\n",
      "Epoch 110/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1795 - val_accuracy: 0.0000e+00 - val_loss: 0.1799\n",
      "Epoch 111/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1802 - val_accuracy: 0.0000e+00 - val_loss: 0.1806\n",
      "Epoch 112/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 113/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1805 - val_accuracy: 0.0000e+00 - val_loss: 0.1794\n",
      "Epoch 114/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1799 - val_accuracy: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 115/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
      "Epoch 116/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1803 - val_accuracy: 0.0000e+00 - val_loss: 0.1818\n",
      "Epoch 117/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 7.9917e-05 - loss: 0.1828 - val_accuracy: 0.0000e+00 - val_loss: 0.1781\n",
      "Epoch 118/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1804 - val_accuracy: 0.0000e+00 - val_loss: 0.1788\n",
      "Epoch 119/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1795 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 120/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1798 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 121/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1807 - val_accuracy: 0.0000e+00 - val_loss: 0.1891\n",
      "Epoch 122/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1822 - val_accuracy: 0.0000e+00 - val_loss: 0.1784\n",
      "Epoch 123/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1790 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
      "Epoch 124/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1794 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
      "Epoch 125/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1847\n",
      "Epoch 126/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1809 - val_accuracy: 0.0000e+00 - val_loss: 0.1830\n",
      "Epoch 127/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1798 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
      "Epoch 128/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1784\n",
      "Epoch 129/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1791 - val_accuracy: 0.0000e+00 - val_loss: 0.1778\n",
      "Epoch 130/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1797 - val_accuracy: 0.0000e+00 - val_loss: 0.1808\n",
      "Epoch 131/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1811 - val_accuracy: 0.0000e+00 - val_loss: 0.1792\n",
      "Epoch 132/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 7.9917e-05 - loss: 0.1795 - val_accuracy: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 133/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
      "Epoch 134/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1795 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
      "Epoch 135/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1788 - val_accuracy: 0.0000e+00 - val_loss: 0.1779\n",
      "Epoch 136/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1787 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
      "Epoch 137/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1828\n",
      "Epoch 138/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1792 - val_accuracy: 0.0000e+00 - val_loss: 0.1821\n",
      "Epoch 139/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1827\n",
      "Epoch 140/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1800 - val_accuracy: 0.0000e+00 - val_loss: 0.1838\n",
      "Epoch 141/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1792\n",
      "Epoch 142/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1789 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
      "Epoch 143/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1790 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 144/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1797 - val_accuracy: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 145/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1781 - val_accuracy: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 146/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1781 - val_accuracy: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 147/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1782 - val_accuracy: 0.0000e+00 - val_loss: 0.1798\n",
      "Epoch 148/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1790 - val_accuracy: 0.0000e+00 - val_loss: 0.1780\n",
      "Epoch 149/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1793 - val_accuracy: 0.0000e+00 - val_loss: 0.1835\n",
      "Epoch 150/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1793 - val_accuracy: 0.0000e+00 - val_loss: 0.1791\n",
      "Epoch 151/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
      "Epoch 152/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1786 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
      "Epoch 153/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1782 - val_accuracy: 0.0000e+00 - val_loss: 0.1822\n",
      "Epoch 154/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1786 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
      "Epoch 155/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1789 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
      "Epoch 156/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1784 - val_accuracy: 0.0000e+00 - val_loss: 0.1790\n",
      "Epoch 157/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1787 - val_accuracy: 0.0000e+00 - val_loss: 0.1793\n",
      "Epoch 158/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1799 - val_accuracy: 0.0000e+00 - val_loss: 0.1816\n",
      "Epoch 159/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1827 - val_accuracy: 0.0000e+00 - val_loss: 0.1859\n",
      "Epoch 160/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1791 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
      "Epoch 161/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1783 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
      "Epoch 162/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
      "Epoch 163/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1782 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
      "Epoch 164/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1809\n",
      "Epoch 165/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1783 - val_accuracy: 0.0000e+00 - val_loss: 0.1810\n",
      "Epoch 166/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 167/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1781 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
      "Epoch 168/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 169/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1780 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
      "Epoch 170/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1804\n",
      "Epoch 171/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1783 - val_accuracy: 0.0000e+00 - val_loss: 0.1815\n",
      "Epoch 172/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
      "Epoch 173/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1774 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 174/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1789 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 175/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1769 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
      "Epoch 176/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1844\n",
      "Epoch 177/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1779 - val_accuracy: 0.0000e+00 - val_loss: 0.1845\n",
      "Epoch 178/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1777 - val_accuracy: 0.0000e+00 - val_loss: 0.1809\n",
      "Epoch 179/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 180/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1785 - val_accuracy: 0.0000e+00 - val_loss: 0.1802\n",
      "Epoch 181/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1773 - val_accuracy: 0.0000e+00 - val_loss: 0.1813\n",
      "Epoch 182/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1773 - val_accuracy: 0.0000e+00 - val_loss: 0.1834\n",
      "Epoch 183/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1788\n",
      "Epoch 184/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1811\n",
      "Epoch 185/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1768 - val_accuracy: 0.0000e+00 - val_loss: 0.1805\n",
      "Epoch 186/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1768 - val_accuracy: 0.0000e+00 - val_loss: 0.1817\n",
      "Epoch 187/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 188/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1771 - val_accuracy: 0.0000e+00 - val_loss: 0.1800\n",
      "Epoch 189/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 7.9917e-05 - loss: 0.1780 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 190/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1768 - val_accuracy: 0.0000e+00 - val_loss: 0.1862\n",
      "Epoch 191/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1771 - val_accuracy: 0.0000e+00 - val_loss: 0.1812\n",
      "Epoch 192/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1772 - val_accuracy: 0.0000e+00 - val_loss: 0.1867\n",
      "Epoch 193/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1796 - val_accuracy: 0.0000e+00 - val_loss: 0.1841\n",
      "Epoch 194/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1766 - val_accuracy: 0.0000e+00 - val_loss: 0.1819\n",
      "Epoch 195/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1775 - val_accuracy: 0.0000e+00 - val_loss: 0.1821\n",
      "Epoch 196/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1766 - val_accuracy: 0.0000e+00 - val_loss: 0.1887\n",
      "Epoch 197/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 7.9917e-05 - loss: 0.1770 - val_accuracy: 0.0000e+00 - val_loss: 0.1824\n",
      "Epoch 198/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 7.9917e-05 - loss: 0.1762 - val_accuracy: 0.0000e+00 - val_loss: 0.1835\n",
      "Epoch 199/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 7.9917e-05 - loss: 0.1770 - val_accuracy: 0.0000e+00 - val_loss: 0.1803\n",
      "Epoch 200/200\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 7.9917e-05 - loss: 0.1769 - val_accuracy: 0.0000e+00 - val_loss: 0.1865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d19448ee40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train2, y_train2, epochs=iterations, validation_split=0.05, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40eef300-0aa6-4982-8d70-9f7c9725771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "1551\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model.predict(x_test2)\n",
    "print(len(predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e203510c-d93e-49b0-82f1-e6cb7b251417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425631\n",
      "\u001b[1m13301/13301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "DR19x2 = np.dstack([data_masked['teff'],data_masked['logg'], data_masked['m_h_atm'],\n",
    "                   data_masked['alpha_m_atm'], data_masked['c_h'], data_masked['n_h']])[0]\n",
    "print(len(data_masked['teff']))\n",
    "\n",
    "DR19x2= DR19x2/scaling_x2\n",
    "predictionsDR19_2 = model.predict(DR19x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c82f539-21c2-4d83-a2bb-ff8aaccbba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Pulling Labels and Data\n",
    "apokasc2_age = predictionsDR19.flatten()\n",
    "tess_age = predictionsDR19_2.flatten()\n",
    "age_difference = tess_age - apokasc2_age\n",
    "star_ids = data_masked['tic_v8_id']\n",
    "#Creating DataFrame of the results\n",
    "dataframe = pd.DataFrame({\n",
    "\t\"TIC\": star_ids,\n",
    "\t'TESS_predicted_Gyr': tess_age,\n",
    "\t'APOKASC2_predicted_Gyr': tess_age,\n",
    "    'Difference': age_difference\n",
    "})\n",
    "#Saving DataFrame to CSV\n",
    "dataframe.to_csv('TESS_APOKASC2_Comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99d43871-b400-4d2c-8dc3-8dfca1296571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference between data set is: -0.30940393\n"
     ]
    }
   ],
   "source": [
    "print(f'Average difference between data set is:', np.mean(age_difference))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
